{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PKKarthikeya2005/LMS/blob/main/All_NLP_Tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a1b60aa",
      "metadata": {
        "id": "7a1b60aa"
      },
      "outputs": [],
      "source": [
        "!pip install blis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc64e3b1",
      "metadata": {
        "id": "dc64e3b1"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5216183b",
      "metadata": {
        "id": "5216183b"
      },
      "source": [
        "### Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b84969b",
      "metadata": {
        "id": "7b84969b"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "\n",
        "text = \"Hello! How are you? I am learning NLP. Welcome to U.S.A. \"\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "spacy_tokens = [token.text for token in doc]\n",
        "\n",
        "print(\"Word Tokens:\", word_tokens)\n",
        "print(\"Sentence Tokens:\", sent_tokens)\n",
        "print(\"SpaCy Tokens:\", spacy_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5131cd7d",
      "metadata": {
        "id": "5131cd7d"
      },
      "source": [
        "### Stop word removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6af739f",
      "metadata": {
        "id": "e6af739f"
      },
      "outputs": [],
      "source": [
        "spacy_stopwords = [token.text for token in doc if not token.is_stop]\n",
        "\n",
        "print(\"SpaCy Filtered Words:\", spacy_stopwords)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a93168",
      "metadata": {
        "id": "67a93168"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccb1a670",
      "metadata": {
        "id": "ccb1a670"
      },
      "outputs": [],
      "source": [
        "lemmatized_words = [token.lemma_ for token in doc]\n",
        "\n",
        "print(\"Lemmatized Words:\", lemmatized_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cd89318",
      "metadata": {
        "id": "7cd89318"
      },
      "source": [
        "### Lower casr and Remove Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef527c7",
      "metadata": {
        "id": "9ef527c7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "text = \"Hello!! This is NLP 101. Visit https://example.com\"\n",
        "cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "lower_text = cleaned_text.lower()\n",
        "\n",
        "print(\"Cleaned Text:\", lower_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a0ac363",
      "metadata": {
        "id": "6a0ac363"
      },
      "source": [
        "### parts of Speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d27f705",
      "metadata": {
        "id": "6d27f705"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(f\"{token.text} --> {token.pos_}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b498637f",
      "metadata": {
        "id": "b498637f"
      },
      "source": [
        "### NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4946e2d",
      "metadata": {
        "id": "a4946e2d"
      },
      "outputs": [],
      "source": [
        "for ent in doc.ents:\n",
        "    print(f\"{ent.text} --> {ent.label_}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2e33063",
      "metadata": {
        "id": "a2e33063"
      },
      "source": [
        "### Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eee615b",
      "metadata": {
        "id": "2eee615b"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "\n",
        "model = Word2Vec(sentences=common_texts, vector_size=2, window=5, min_count=1, workers=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b1e4013",
      "metadata": {
        "id": "5b1e4013"
      },
      "source": [
        "#### Embeddings for a word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9e71c4d",
      "metadata": {
        "id": "a9e71c4d"
      },
      "outputs": [],
      "source": [
        "print(\"Vector for 'computer':\", model.wv['computer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed8624bb",
      "metadata": {
        "id": "ed8624bb"
      },
      "source": [
        "#### Most similar words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d155c3",
      "metadata": {
        "id": "70d155c3"
      },
      "outputs": [],
      "source": [
        "print(\"Most similar words to 'computer':\", model.wv.most_similar('eps'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d2f1fc",
      "metadata": {
        "id": "31d2f1fc"
      },
      "source": [
        "#### Visualizing closest words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f24c06a",
      "metadata": {
        "id": "9f24c06a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "word_vectors = model.wv[model.wv.index_to_key]  # Get the word vectors\n",
        "pca = PCA(n_components=2)  # Initialize PCA\n",
        "result = pca.fit_transform(word_vectors)  # Fit and transform the word vectors\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(result[:, 0], result[:, 1])\n",
        "\n",
        "\n",
        "words = list(model.wv.index_to_key)\n",
        "for i, word in enumerate(words):\n",
        "    plt.annotate(word, xy=(result[i, 0], result[i, 1]), fontsize=12)\n",
        "\n",
        "plt.title(\"Word Embeddings Visualization\")\n",
        "plt.xlabel(\"PCA Component 1\")\n",
        "plt.ylabel(\"PCA Component 2\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18faf036",
      "metadata": {
        "id": "18faf036"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}